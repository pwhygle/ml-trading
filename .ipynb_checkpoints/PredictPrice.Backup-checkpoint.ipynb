{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb87b53-0562-48a4-b94b-24b6574ddfca",
   "metadata": {},
   "source": [
    "Declare Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca5ca63-8452-4672-aa62-0f4a0483b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AMC\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fba166-42c7-4e3b-a36b-f855e9d298d2",
   "metadata": {},
   "source": [
    "Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0115beaa-cd69-48f7-9f2c-553b9c47f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44658201-a076-4c11-9013-82b237659d9e",
   "metadata": {},
   "source": [
    "Load the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a177bd48-dc80-402c-a10d-6c181488df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WhyglePa\\source\\repos\\algo-trading\\src\\Python\\TDAmeritrade\\Notebook\\ML\\Data\\AMC.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             Date   Open   High    Low  Close  Adj Close     Volume\n",
       "1237  2018-11-15  15.50  15.51  14.74  14.74  13.438042    2166000\n",
       "1238  2018-11-16  14.65  14.75  13.99  14.05  12.808989    2505200\n",
       "1239  2018-11-19  14.05  14.30  13.20  13.49  12.298451    2973500\n",
       "1240  2018-11-20  13.22  13.71  13.04  13.29  12.116117    3077300\n",
       "1241  2018-11-21  13.42  14.25  13.38  13.94  12.708704    1631900\n",
       "...          ...    ...    ...    ...    ...        ...        ...\n",
       "1732  2020-11-04   2.40   2.43   2.24   2.31   2.310000    7609100\n",
       "1733  2020-11-05   2.35   2.57   2.27   2.46   2.460000    8056200\n",
       "1734  2020-11-06   2.43   2.62   2.33   2.49   2.490000    9049500\n",
       "1735  2020-11-09   4.27   4.39   3.23   3.77   3.770000  132511000\n",
       "1736  2020-11-10   3.99   4.03   3.34   3.51   3.510000   42129300\n",
       "\n",
       "[500 rows x 7 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"C:\\\\Users\\\\WhyglePa\\\\source\\\\repos\\\\algo-trading\\\\src\\\\Python\\\\TDAmeritrade\\\\Notebook\\\\ML\\\\Data\\\\\" + ticker + \".csv\"\n",
    "print(file)\n",
    "dataset_train = pd.read_csv(file).tail(1000).head(500)\n",
    "dataset_train.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3467c-3759-4125-b0b8-4de2080c5b2e",
   "metadata": {},
   "source": [
    "Normalize the Data to Train Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4614ccf0-5dc0-45e2-bc68-9806fb6dc5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>0.925156</td>\n",
       "      <td>0.894237</td>\n",
       "      <td>0.888194</td>\n",
       "      <td>0.872502</td>\n",
       "      <td>0.843566</td>\n",
       "      <td>2166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>0.866251</td>\n",
       "      <td>0.842712</td>\n",
       "      <td>0.836111</td>\n",
       "      <td>0.824948</td>\n",
       "      <td>0.796846</td>\n",
       "      <td>2505200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.824671</td>\n",
       "      <td>0.812203</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.786354</td>\n",
       "      <td>0.758928</td>\n",
       "      <td>2973500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2018-11-20</td>\n",
       "      <td>0.767152</td>\n",
       "      <td>0.772203</td>\n",
       "      <td>0.770139</td>\n",
       "      <td>0.772571</td>\n",
       "      <td>0.745386</td>\n",
       "      <td>3077300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2018-11-21</td>\n",
       "      <td>0.781012</td>\n",
       "      <td>0.808814</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.817367</td>\n",
       "      <td>0.789398</td>\n",
       "      <td>1631900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.020139</td>\n",
       "      <td>0.015851</td>\n",
       "      <td>0.017082</td>\n",
       "      <td>7609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>0.013860</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.026189</td>\n",
       "      <td>0.028223</td>\n",
       "      <td>8056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>0.019404</td>\n",
       "      <td>0.020339</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.028256</td>\n",
       "      <td>0.030451</td>\n",
       "      <td>9049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>0.146916</td>\n",
       "      <td>0.140339</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.116471</td>\n",
       "      <td>0.125517</td>\n",
       "      <td>132511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>2020-11-10</td>\n",
       "      <td>0.127512</td>\n",
       "      <td>0.115932</td>\n",
       "      <td>0.096528</td>\n",
       "      <td>0.098553</td>\n",
       "      <td>0.106207</td>\n",
       "      <td>42129300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      Open      High       Low     Close  Adj Close     Volume\n",
       "1237  2018-11-15  0.925156  0.894237  0.888194  0.872502   0.843566    2166000\n",
       "1238  2018-11-16  0.866251  0.842712  0.836111  0.824948   0.796846    2505200\n",
       "1239  2018-11-19  0.824671  0.812203  0.781250  0.786354   0.758928    2973500\n",
       "1240  2018-11-20  0.767152  0.772203  0.770139  0.772571   0.745386    3077300\n",
       "1241  2018-11-21  0.781012  0.808814  0.793750  0.817367   0.789398    1631900\n",
       "...          ...       ...       ...       ...       ...        ...        ...\n",
       "1732  2020-11-04  0.017325  0.007458  0.020139  0.015851   0.017082    7609100\n",
       "1733  2020-11-05  0.013860  0.016949  0.022222  0.026189   0.028223    8056200\n",
       "1734  2020-11-06  0.019404  0.020339  0.026389  0.028256   0.030451    9049500\n",
       "1735  2020-11-09  0.146916  0.140339  0.088889  0.116471   0.125517  132511000\n",
       "1736  2020-11-10  0.127512  0.115932  0.096528  0.098553   0.106207   42129300\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_training_set = dataset_train.copy()\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range= (0,1))\n",
    "scaled_training_set[['Open']] = scaler.fit_transform(scaled_training_set[['Open']])\n",
    "scaled_training_set[['High']] = scaler.fit_transform(scaled_training_set[['High']])\n",
    "scaled_training_set[['Low']] = scaler.fit_transform(scaled_training_set[['Low']])\n",
    "scaled_training_set[['Close']] = scaler.fit_transform(scaled_training_set[['Close']])\n",
    "scaled_training_set[['Adj Close']] = scaler.fit_transform(scaled_training_set[['Adj Close']])\n",
    "\n",
    "scaled_training_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94906e68-0de5-4eea-a6d5-81bc28082c1b",
   "metadata": {},
   "source": [
    "Creating X_train and y_train Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "1da23e34-03b8-4ab9-a743-4985c3604c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2020-08-14' 0.23631323631323634 0.22440677966101694 ...\n",
      "  0.23845623707787733 0.2569754729537028 12055800]\n",
      " ['2020-08-17' 0.2474012474012474 0.23932203389830506 ...\n",
      "  0.24259131633356307 0.2614316950280444 7159200]\n",
      " ['2020-08-18' 0.23700623700623705 0.2203389830508475 ...\n",
      "  0.2253618194348725 0.24286410305162084 5790700]\n",
      " ...\n",
      " ['2019-02-11' 0.8031878031878034 0.7776271186440677 ...\n",
      "  0.7643004824259132 0.7496204784200019 1696300]\n",
      " ['2019-02-12' 0.7657657657657658 0.7484745762711864 ...\n",
      "  0.7705031013094419 0.7557988817853407 2302400]\n",
      " ['2019-02-13' 0.7726957726957728 0.7586440677966102 ...\n",
      "  0.7877325982081324 0.7729610555898848 1515300]]\n",
      "[['2020-11-06' 0.019404019404019424 0.02033898305084747 ...\n",
      "  0.02825637491385255 0.030450850841334726 9049500]\n",
      " ['2020-11-05' 0.01386001386001387 0.01694915254237289 ...\n",
      "  0.026188835286009654 0.02822273980416387 8056200]\n",
      " ['2020-11-04' 0.017325017325017317 0.007457627118644089 ...\n",
      "  0.015851137146795313 0.01708218461830971 7609100]\n",
      " ...\n",
      " ['2019-02-15' 0.8024948024948027 0.8013559322033899 ...\n",
      "  0.8070296347346658 0.7921827466964539 1017300]\n",
      " ['2019-02-14' 0.7823977823977825 0.7918644067796611 ...\n",
      "  0.7973811164713991 0.7825717897376175 1173500]\n",
      " ['2019-02-13' 0.7726957726957728 0.7586440677966102 ...\n",
      "  0.7877325982081324 0.7729610555898848 1515300]]\n",
      "(26340, 1, 1)\n",
      "(26340, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "rg = scaled_training_set.shape[0] -1\n",
    "X = scaled_training_set.head(0)\n",
    "Y = scaled_training_set.head(0)\n",
    "\n",
    "for i in range(60, rg):\n",
    "    df = pd.DataFrame(scaled_training_set.head(i).tail(60))\n",
    "    #print(df)\n",
    "    X = pd.concat([df, X])\n",
    "    \n",
    "    df = pd.DataFrame(scaled_training_set.head(i).tail(1))\n",
    "    #print(df)\n",
    "    #Y.append(df)\n",
    "    Y = pd.concat([df, Y])\n",
    "\n",
    "#print(X)\n",
    "#print(Y)\n",
    "\n",
    "X_train = X.to_numpy()\n",
    "Y_train = Y.to_numpy()\n",
    "#print(X_train)\n",
    "#print(X_train.shape)\n",
    "#print(Y_train.shape)\n",
    "\n",
    "print(X_train)\n",
    "print(Y_train)\n",
    "\n",
    "X_train = X.loc[:, X.columns == 'Open']\n",
    "Y_train = X.loc[:, Y.columns == 'Open']\n",
    "\n",
    "X_train = np.array(Xtrain)\n",
    "Y_train = np.array(Ytrain)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16991e-af9c-43af-b111-f1469546cab3",
   "metadata": {},
   "source": [
    "# Reshape the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "7214dfba-1b1c-4fe5-8beb-41e589b01ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26340, 1, 1)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f9354-79f4-4c9c-9af2-e7fff1aa158e",
   "metadata": {},
   "source": [
    "Building the Model by Importing the Crucial Libraries and Adding Different Layers to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "a3e0c305-1a75-4f45-9917-38f1d5ad1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences= True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50, return_sequences= True))\n",
    "regressor.add(Dropout(0.2))\n",
    "              \n",
    "regressor.add(LSTM(units=50, return_sequences= True))\n",
    "regressor.add(Dropout(0.2))\n",
    "              \n",
    "regressor.add(LSTM(units=50))\n",
    "regressor.add(Dropout(0.2))\n",
    "              \n",
    "regressor.add(Dense(units=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fca801-5f35-478c-a9c6-4b34742992b8",
   "metadata": {},
   "source": [
    "Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8d652a-7724-488c-b289-994655e9c87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/824 [===========>..................] - ETA: 10s - loss: 0.0373"
     ]
    }
   ],
   "source": [
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "#print(X_train[4])\n",
    "\n",
    "regressor.fit(X_train, Y_train, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab775386-de61-4c57-95e2-801b0f22ff42",
   "metadata": {},
   "source": [
    "Extracting the Actual Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "b7f6b0f7-2e08-47db-b941-171c26a62007",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv(\"C:\\\\Users\\\\WhyglePa\\\\source\\\\repos\\\\algo-trading\\\\src\\\\Python\\\\TDAmeritrade\\\\Notebook\\\\ML\\\\Data\\\\\" + ticker + \".csv\").tail(1000)\n",
    "actual_stock_price = dataset_test.iloc[:,1:2].values\n",
    "#print(actual_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a807cb73-4fc6-41be-915d-be6c8d8e6e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.5  14.65 14.05 ...  6.26  5.75  5.83]\n",
      "[[0.99670834]\n",
      " [0.93357852]\n",
      " [0.8890163 ]\n",
      " ...\n",
      " [0.31045014]\n",
      " [0.27257225]\n",
      " [0.27851388]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)\n",
    "ln = len(dataset_total)- len(dataset_test)-60\n",
    "#print(ln)\n",
    "inputs = dataset_total[ln:].values\n",
    "\n",
    "inputs = dataset_total.iloc[:,1].values\n",
    "print(inputs)\n",
    "inputs = inputs.reshape(-1,1)\n",
    "\n",
    "inputs = scaler.transform(inputs)\n",
    "print(inputs)\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1254f-628c-4063-bfcb-c201c828e90b",
   "metadata": {},
   "source": [
    "Predicting the Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "ebd76349-71e2-4d3f-b25b-1e7b6c92a5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 60, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_21\" is incompatible with the layer: expected shape=(None, 1, 1), found shape=(32, 60, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [384], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 2\u001b[0m predicted_stock_price \u001b[38;5;241m=\u001b[39m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m predicted_stock_price \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(predicted_stock_price)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filena3_xb8n.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_21\" is incompatible with the layer: expected shape=(None, 1, 1), found shape=(32, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c6b17-dc7d-4a10-b89e-6af4bf5a7740",
   "metadata": {},
   "source": [
    "Plotting the Actual and Predicted Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7399e5b-b779-4873-ad0b-11ff8675d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax1 = plt.subplots()\n",
    "first_dt = dataset_train.head(1).iloc[0,0]\n",
    "print(first_dt)\n",
    "\n",
    "last_dt = dataset_test.tail(1).iloc[0,0]\n",
    "print(last_dt)\n",
    "\n",
    "# NEED TO GET DATES ON DATA\n",
    "# ax1.set_xlim(np.datetime64(first_dt), np.datetime64(last_dt))\n",
    "\n",
    "plt.plot(actual_stock_price, color = 'red', label = 'Actual Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Price')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "monthyearFmt = mdates.DateFormatter('%Y %B')\n",
    "ax1.xaxis.set_major_formatter(monthyearFmt)\n",
    "_ = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cce5f3-fac0-4775-8db3-de827f0d6c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
